
import data_plotter
# Training of feed forward net
feedforward_training_loss = [0.14220687747001648, 0.1421930491924286, 0.14272913336753845, 0.0036195460706949234, 0.006528798490762711, 0.0069086081348359585, 0.007982615381479263, 0.006752013228833675, 0.019198644906282425, 0.014766493812203407, 0.011878292076289654, 0.018387028947472572, 0.019843686372041702, 0.005712343379855156, 0.011369572021067142, 0.011497565545141697, 0.012697515077888966, 0.010294563136994839, 0.010696757584810257]

c_train = [0.8435, 0.8392, 0.8412, 0.84315, 0.84155, 0.84365, 0.83955, 0.8418, 0.8404, 0.84485]
c_dev = [0.8076, 0.812, 0.8144, 0.8204, 0.8176, 0.8144, 0.8168, 0.8148, 0.8212, 0.8276]
c_parm = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]


nf_train = [0.834, 0.84135, 0.8388, 0.8405, 0.85105, 0.84835, 0.8494, 0.85305]
nf_dev = [0.814, 0.8168, 0.8092, 0.8116, 0.8252, 0.8272, 0.8228, 0.8264]
nf_parm = [100, 150, 200, 250, 300, 350, 400, 450]

# data_plotter.plot(yData=[nf_train, nf_dev], Labels=["Training Data", "Dev Data"], xData=[nf_parm, nf_parm], plotTitle="Performance Curve", xTitle="Doc2Vec Number of Features", yTitle="Accuracy")
# data_plotter.plot(yData=[c_train, c_dev], Labels=["Training Data", "Dev Data"], xData=[c_parm, c_parm], plotTitle="Performance Curve", xTitle="Doc2Vec Context", yTitle="Accuracy")

h1_train = [0.5014, 0.84505, 0.84355, 0.8485, 0.84635, 0.848]
h1_dev = [0.4904, 0.814, 0.8132, 0.8172, 0.8228, 0.8164]
h1_parm = [40, 30, 25, 20, 15, 10]


h2_train = [0.8482, 0.84195, 0.84585, 0.8502]
h2_dev = [0.8164, 0.8128, 0.8208, 0.8136]
h2_parm = [10, 8, 6, 4]

lr_train = [0.84815, 0.5014, 0.5014, 0.5014, 0.5014]
lr_dev = [0.8172, 0.4904, 0.4904, 0.4904, 0.4904]
lr_parm = [1, 0.5, 0.1, 0.05, 0.01]

# data_plotter.plot(yData=[h1_train, h1_dev], Labels=["Training Data", "Dev Data"], xData=[h1_parm, h1_parm], plotTitle="Performance Curve", xTitle="Hidden Layer 1 Size", yTitle="Accuracy")
# data_plotter.plot(yData=[h2_train, h2_dev], Labels=["Training Data", "Dev Data"], xData=[h2_parm, h2_parm], plotTitle="Performance Curve", xTitle="Hidden Layer 2 Size", yTitle="Accuracy")
# data_plotter.plot(yData=[lr_train, lr_dev], Labels=["Training Data", "Dev Data"], xData=[lr_parm, lr_parm], plotTitle="Performance Curve", xTitle="Learning Rate", yTitle="Accuracy")

training_loss = [0.19248534739017487, 0.19629718363285065, 0.19745929539203644, 0.19798509776592255, 0.1982760727405548, 0.19845767319202423, 0.19858036935329437, 0.1986679583787918, 0.1987328678369522, 0.19878220558166504, 0.19882012903690338, 0.19884897768497467, 0.19887001812458038, 0.19888338446617126, 0.19888819754123688, 0.19888195395469666, 0.19885899126529694, 0.1988067626953125, 0.19869168102741241, 0.19838407635688782, 0.19663508236408234, 0.059396035969257355, 0.0014911602484062314, 0.001772357732988894, 0.0019164704717695713, 0.002002836437895894, 0.0020285150967538357, 0.00201936112716794, 0.001993000041693449, 0.00195986102335155, 0.0019259981345385313, 0.0018944615731015801, 0.0018664628732949495, 0.0018419947009533644, 0.0018203271320089698, 0.0018005475867539644, 0.0017818533815443516, 0.0017638951539993286, 0.001746643683873117, 0.00173013040330261, 0.0017143005970865488, 0.001699026208370924, 0.0016841714968904853, 0.00166967639233917, 0.0016556998016312718, 0.0016430290415883064, 0.0016327324556186795, 0.00162630551494658, 0.0016257244860753417, 0.0016334430547431111]
iterations = range(len(training_loss))

data_plotter.plot(yData=[training_loss], Labels=["Training Loss"], xData=[iterations], plotTitle="Training Loss", xTitle="Epochs", yTitle="MSELoss", yTopLimit= 0.008)